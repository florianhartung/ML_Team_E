{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True Shower Regression Baseline\n",
    "\n",
    "Create a baseline using a simple ML algorithm to predict/infer the true shower parameters using a simple ML algorithm\n",
    "- using clean_image_\\*\\_m1 and clean_image_\\*\\_m2 independently\n",
    "- by combining both clean_image_* features with \"hillas\" and/or \"stereo\"\n",
    "\n",
    "Linear regression, polynomial regression, decision tree regression and random forrest regression will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../../../magic-ml-images\")\n",
    "from magicdl import magic\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "SEED = 42\n",
    "gen = torch.Generator().manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = pd.read_parquet(\"../../../data/magic-gammas.parquet\")\n",
    "protons = pd.read_parquet(\"../../../data/magic-protons.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = gammas.dropna()\n",
    "protons = protons.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PIXELS = 1183\n",
    "\n",
    "ts_params = [\n",
    "    \"true_energy\", \n",
    "    \"true_theta\",\n",
    "    \"true_phi\", \n",
    "    \"true_telescope_theta\", \n",
    "    \"true_telescope_phi\",\n",
    "    \"true_first_interaction_height\",\n",
    "    \"true_impact_m1\",\n",
    "    \"true_impact_m2\"\n",
    "]\n",
    "hillas_params = [\n",
    "    \"hillas_length_m1\",\n",
    "    \"hillas_width_m1\",\n",
    "    \"hillas_delta_m1\",\n",
    "    \"hillas_size_m1\",\n",
    "    \"hillas_cog_x_m1\",\n",
    "    \"hillas_cog_y_m1\",\n",
    "    \"hillas_sin_delta_m1\",\n",
    "    \"hillas_cos_delta_m1\",\n",
    "    \"hillas_length_m2\",\n",
    "    \"hillas_width_m2\",\n",
    "    \"hillas_delta_m2\",\n",
    "    \"hillas_size_m2\",\n",
    "    \"hillas_cog_x_m2\",\n",
    "    \"hillas_cog_y_m2\",\n",
    "    \"hillas_sin_delta_m2\",\n",
    "    \"hillas_cos_delta_m2\"\n",
    "]\n",
    "stereo_params = [\n",
    "    \"stereo_direction_x\",       \n",
    "    \"stereo_direction_y\",       \n",
    "    \"stereo_zenith\",            \n",
    "    \"stereo_azimuth\",           \n",
    "    \"stereo_dec\",               \n",
    "    \"stereo_ra\",                \n",
    "    \"stereo_theta2\",            \n",
    "    \"stereo_core_x\",            \n",
    "    \"stereo_core_y\",            \n",
    "    \"stereo_impact_m1\",         \n",
    "    \"stereo_impact_m2\",         \n",
    "    \"stereo_impact_azimuth_m1\", \n",
    "    \"stereo_impact_azimuth_m2\", \n",
    "    \"stereo_shower_max_height\", \n",
    "    \"stereo_xmax\",              \n",
    "    \"stereo_cherenkov_radius\",  \n",
    "    \"stereo_cherenkov_density\", \n",
    "    \"stereo_baseline_phi_m1\",   \n",
    "    \"stereo_baseline_phi_m2\",   \n",
    "    \"stereo_image_angle\",   \n",
    "    \"stereo_cos_between_shower\"\n",
    "]\n",
    "\n",
    "# split the dataset:\n",
    "\n",
    "num_protons = len(protons)\n",
    "num_gammas = len(gammas)\n",
    "\n",
    "TRAIN_PORTION = 0.6\n",
    "TEST_PORTION = 0.2\n",
    "# VAL_PORTION is the rest\n",
    "\n",
    "train_size_protons = int(TRAIN_PORTION * num_protons)\n",
    "test_size_protons = int(TEST_PORTION * num_protons)\n",
    "val_size_protons = num_protons - train_size_protons - test_size_protons\n",
    "\n",
    "train_size_gammas = int(TRAIN_PORTION * num_gammas)\n",
    "test_size_gammas = int(TEST_PORTION * num_gammas)\n",
    "val_size_gammas = num_gammas - train_size_gammas - test_size_gammas\n",
    "\n",
    "protons_indices = torch.randperm(num_protons, generator=gen)\n",
    "gammas_indices = torch.randperm(num_gammas, generator=gen)\n",
    "\n",
    "protons_train_indices = protons_indices[:train_size_protons]\n",
    "protons_val_indices = protons_indices[train_size_protons:train_size_protons+val_size_protons]\n",
    "protons_test_indices = protons_indices[train_size_protons+val_size_protons:]\n",
    "\n",
    "gammas_train_indices = gammas_indices[:train_size_gammas]\n",
    "gammas_val_indices = gammas_indices[train_size_gammas:train_size_gammas+val_size_gammas]\n",
    "gammas_test_indices = gammas_indices[train_size_gammas+val_size_gammas:]\n",
    "\n",
    "protons_train = protons.iloc[protons_train_indices]\n",
    "protons_val = protons.iloc[protons_val_indices]\n",
    "protons_test = protons.iloc[protons_test_indices]\n",
    "gammas_train = gammas.iloc[gammas_train_indices]\n",
    "gammas_val = gammas.iloc[gammas_val_indices]\n",
    "gammas_test = gammas.iloc[gammas_test_indices]\n",
    "\n",
    "# protons_ts = protons[ts_params]\n",
    "# gammas_ts = gammas[ts_params]\n",
    "# protons_clean1 = protons[\"clean_image_m1\"]\n",
    "# gammas_clean1 = gammas[\"clean_image_m1\"]\n",
    "# protons_clean2 = protons[\"clean_image_m2\"]\n",
    "# gammas_clean2 = gammas[\"clean_image_m2\"]\n",
    "# protons_hillas = protons[hillas_params]\n",
    "# gammas_hillas = gammas[hillas_params]\n",
    "# protons_stereo = protons[stereo_params]\n",
    "# gammas_stereo = gammas[stereo_params]\n",
    "\n",
    "y_protons_train = protons_train[ts_params]\n",
    "y_protons_val = protons_val[ts_params]\n",
    "y_protons_test = protons_test[ts_params]\n",
    "y_gammas_train = gammas_train[ts_params]\n",
    "y_gammas_val = gammas_val[ts_params]\n",
    "y_gammas_test = gammas_test[ts_params]\n",
    "\n",
    "# normalise data:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalise(train, val, test):\n",
    "    scaler = StandardScaler()\n",
    "    train_new = scaler.fit_transform(train.copy())\n",
    "    val_new = scaler.transform(val)\n",
    "    test_new = scaler.transform(test)\n",
    "    return (train_new, val_new, test_new), scaler\n",
    "\n",
    "(y_protons_train, y_protons_val, y_protons_test), y_proton_scaler = normalise(y_protons_train, y_protons_val, y_protons_test)\n",
    "\n",
    "(y_gammas_train, y_gammas_val, y_gammas_test), y_gamma_scaler = normalise(y_gammas_train, y_gammas_val, y_gammas_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'linear_regression' from '/home/teame/ML_Team_E/src/infer_true_shower_parameters/baseline/linear_regression.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import linear_regression\n",
    "from linear_regression import LinearRegression\n",
    "import importlib\n",
    "importlib.reload(linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training only on clean_image_m1\n",
    "#### Protons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_protons_train, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_protons_val, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_protons_test, dtype=torch.float32)\n",
    "\n",
    "X_train = np.array(protons_train[\"clean_image_m1\"].tolist())\n",
    "X_val = np.array(protons_val[\"clean_image_m1\"].tolist())\n",
    "X_test = np.array(protons_test[\"clean_image_m1\"].tolist())\n",
    "\n",
    "(X_train, X_val, X_test), _ = normalise(X_train, X_val, X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teame/ML_Team_E/src/infer_true_shower_parameters/baseline/linear_regression.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n",
      "/home/teame/ML_Team_E/src/infer_true_shower_parameters/baseline/linear_regression.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n",
      "/home/teame/ML_Team_E/src/infer_true_shower_parameters/baseline/linear_regression.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression(NUM_PIXELS)\n",
    "\n",
    "linreg.fit(X_train, y_train, lr=0.0001)\n",
    "\n",
    "y_pred_val = linreg.predict(X_val)\n",
    "y_pred_train = linreg.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float32(1.061619), np.float32(1.056821))\n"
     ]
    }
   ],
   "source": [
    "mse_val = np.mean((y_pred_val - y_val.numpy())**2)\n",
    "mse_train = np.mean((y_pred_train - y_train.numpy())**2)\n",
    "print((mse_train, mse_val))\n",
    "\n",
    "# ss_res = np.sum((y_pred - y_val.numpy())**2)\n",
    "# ss_tot = np.sum((y_val.numpy() - np.mean(y_val.numpy(), axis=0))**2)\n",
    "# r2_score = 1 - (ss_res / ss_tot)\n",
    "# print(f\"R^2 Score: {r2_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MAGICuda)",
   "language": "python",
   "name": "magicuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
